---
title: "Readme (23761067)"
author: "Talyah Greyling" 
output: 
    html_document:
        css: styles.css
---

### Goals: 
    (1) Transform and clean data
    (2) Exploratory data description of wine review data 
    (3) Statistical modeling of wine review data

### Setup defaults         
```{r setup}

knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      cache = FALSE,
                      fig.align = "center",
                      fig.pos = "H", 
                      fig.width = 6, 
                      fig.height = 5) 
                      
```

### Housekeeping
```{r housekeeping}

# Clear environment
rm(list = ls())           ############ uncomment before final submission 

# Load necessary packages
pacman::p_load(bonsai,
               broom,
               dbbasic, 
               dplyr,
               ggplot2,
               ggwordcloud,
               glue,
               here, 
               kableExtra, 
               knitr,
               ldatuning,                   ############# update @ both rmd's
               modeltime,
               pacman,
               pdp,
               quanteda,
               randomForest,
               readr,
               remotes,
               stopwords,
               stringr,
               targets,
               tidymodels,
               tidyr,
               tidytext, 
               tidyverse,
               topicmodels,
               vip,
               wordcloud,
               xtable)

# Suppress scientific notation  
options(scipen = 999)

# Reproducibility
set.seed(777)

# Set theme & colour palette 
palette <- c("#163940", "#3A7370", "#FFC57B", "#FB9072", "#CE677A", "#5c2011")

my_theme <- theme(
  # Title, subtitle, and caption
  plot.title = element_text(colour = "white", size = 16, family = "arial", hjust = 0.5,face = "bold"),
  plot.subtitle = element_text(colour = "white", size = 14, family = "arial"),
  plot.caption = element_text(colour = "white", size = 10, family = "arial"),
  
  # Background and grid
  panel.background = element_blank(),
  plot.background = element_rect(fill = "black", color = "black"),
  panel.grid.major = element_line(color = "white", size = 0.1),
  panel.grid.minor = element_line(color = "white", size = 0.1),
  
  # Axis titles and labels
  axis.title.x = element_text(colour = "white", size = 12,family = "arial", hjust = 0.5,face = "bold"),
  axis.title.y = element_text(colour = "white", size = 12,family = "arial", hjust = 0.5,face = "bold"),
  axis.text.y = element_text(colour = "white", size = 10,family = "arial"),
  axis.text.x = element_text(colour = "white", size = 10,family = "arial"),
  
  # Legend 
  legend.position = "right",
  legend.text = element_text(colour = "white",size = 12, family = "arial"),
  legend.title = element_text(colour = "white",size = 12, family = "arial", hjust = 3,face = "bold"),
  legend.key = element_rect(fill = "black", color = "black"),
  legend.background = element_rect(fill = "black"),
  
  # Other
  axis.ticks = element_blank(),
  strip.text = element_text(colour = "white", size = 12, family = "arial", vjust = 1, hjust = 0.5)
)

# Import data
data <- readRDS("data/calitzdorp.rds")
               
```

## Goal (1): Transform and clean data

### Explore dataset
```{r explore data}

data %>%
    sample_n(1) %>% 
    t

```

#### Table 1: Head of dataframe 
```{r headdata, results = "asis"}

# Create empty table
datatab1 <- data[1:5,] %>% tibble::as_tibble()

# Populate with useful columns 
datatab1 <- datatab1 %>%
    select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count")) 

# Generate Table1
table1 <- kable(datatab1, "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "") %>%
  kable_styling(font_size = 10) 

# Print Table1
print(table1)

```

#### Table 2: Description of variables in datatab
```{r describe data, results = "asis"}

# Create and populate data frame
df1 <- data.frame(
    Variable = c("id", "rating", "note", "language"), 
    Description = c("Identification code of review",
                    "Rating out of 5 assigned to the wine by the reviewer",
                    "Note written about the wine by the reviewer",
                    "Language of the review")
    ) %>% tibble::as_tibble()

# Generate Table2
table2 <- kable(df1, "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "") %>%
  kable_styling(font_size = 10) 

# Print Table2
print(table2)

```

### Preparing dataset for analysis:
* Started with 2298 observations of 107 variables 
* Extracted the 3 variables useful for my research question 
* Only English observations were kept as using APIs for translation is too costly (1667 observations remaining)
* Unnested tokens (30 800 tokens were recorded)
* I followed the standard pre-processing steps of removing punctuation, numbers, symbols, characters and taking everything to lower case
* I also used the default tidyverse stop_words dataset to remove stop words (16 869 tokens remaining) using 3 respective lexicons: snowball (from the tm package), onix (from the ONIX text retrieval system) and smart (from the SMART information retrieval system). 
* All clean tokes were used in the random forrest to avoid unnecessary sampling bias. 
```{r clean tokens}

# Get review data in clean token format 
review_tokens <- data %>%
    filter(str_detect(language, "en")) %>% # filter for only English entries
    select(c(review_id = "id", "rating", "note")) %>%  # extract useful columns 
    unnest_tokens(input = note, 
                  output = word,
                  to_lower = TRUE,
                  strip_punct = TRUE,
                  strip_numeric = TRUE) %>%  
    mutate(word = gsub("_", "", word)) %>% 
    mutate(word = str_extract(word, "[[:alpha:]]+")) %>% 
    anti_join(stop_words, by = join_by(word)) # remove stop words
 
```

## Goal (2): Exploratory data description of wine review data:
* Plot rating frequency of tokens 
* Plot wordcloud of popular words

### Average rating counts
```{r averating}

# Calculate the average rating for each word and its count
words_ratings_counts <- review_tokens %>%
    group_by(word) %>%
    summarise(
        ave_rating = mean(rating, na.rm = TRUE),
        word_count = n(),
        .groups = "drop"
    )
    
```

#### Figure1: Histogram for frequency of average ratings of review tokens
```{r histogram}

# Plot histogram
fig1 <- ggplot(words_ratings_counts, aes(x = ave_rating)) +
  geom_histogram(aes(y = ..count..), binwidth =0.5, bins = 30, fill = "#3A7370", color = "black", alpha = 1) +
  theme_minimal() +
  labs(title = "Histogram of average ratings of review tokens",
       x = "Average Rating", 
       y = "Frequency") 
fig1

ggsave("writeup/fig1.png", plot = fig1, width = 6, height = 5, dpi = 300)

```

### Popular tokens
```{r popular}

# Create an index that determines popular words
words_popular <- words_ratings_counts %>%
    mutate(popularity_index = 0.8 * word_count + 0.2 * ave_rating) %>%
    filter(
        word_count > 10,
        word != "",!is.na(word),!is.na(ave_rating),!is.na(word_count),!is.na(popularity_index)
    ) %>%
    filter(!word %in% stop_words) %>%
    arrange(desc(popularity_index)) %>%
    select(c(word, popularity_index))

```

#### Figure 2: Word cloud of popular words in reviews based on index 
```{r index wordcloud}

# Create Word Cloud
fig2 <- wordcloud(words_popular$word,
                  words_popular$popularity_index,
                  scale = c(4, 1),
                  colors = palette, 
                  bg.color = "white")
fig2

ggsave("writeup/fig2.png", plot = fig2, width = 6, height = 5, dpi = 300)

```

## Goal (3): Statistical modeling of wine review data
* Use 2 step modelling process 
* Step 1: Use RandomForest as a variable selection method (words as columns & ratings as rows) to determine the top 20 words 
    * Plot training & testing data to confirm similar ratings distributions
    * Plot RF performance with different mtry values
    * Visualise top 20 with a variable importance plot 
    * Visualise top 50 in a wordcloud
* Step 2: run an OLS regression of the best words to get coefficients for their probability of determining good ratings

### Step 1: RandomForest
```{r randomforest}

# Convert data to DTM format: 
dtm <- review_tokens %>%
    group_by(review_id, word) %>% 
    summarise(count = n(), .groups = "drop") %>% 
    pivot_wider(names_from = word,
                values_from = count, 
                values_fill = list(count = 0))

# Add back rating & drop review_id
ratings <- review_tokens %>% 
    select(review_id, rating) %>% 
    distinct()
dtm <- left_join(ratings, dtm, by = "review_id") %>% 
    select(-review_id)

# Define training and testing sets for prediction
split_ratings <- initial_split(dtm, prop = 0.7)
training_ratings <- training(split_ratings)
testing_ratings <- testing(split_ratings)
``` 

#### Figure 3: Distribution of training & testing data
```{r traintest distribution}

# Confirm that training & testing data have similar ratings distributions
fig3 <- ggplot() +
        geom_density(data = training_ratings, aes(rating.x), linewidth = 1.5, alpha = 0.5, color = "#CE677A") +
        geom_density(data = testing_ratings, aes(rating.x), linewidth = 1.5, alpha = 0.5, color = "#3A7370") +
        scale_x_continuous(labels = scales::comma) +
        theme_minimal() +
        labs(title = "Ratings Distribution: Train (Red) vs Test (Green)", x = "Rating", y = "Density")

fig3

ggsave("writeup/fig3.png", plot = fig3, width = 6, height = 5, dpi = 300)

``` 

```{r randomforest continued}

# RandomForest recipe
wine_rec <- recipe(rating.x ~ ., data = training_ratings) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())

# RandomForest specification model
model_spec <- rand_forest(
  mtry = tune(),       
  min_n = 10,           
  trees = 100           
  ) %>%
  set_engine("ranger", num.threads = 10, 
             importance = "permutation") %>%  
  set_mode("regression")

# Inspect the low level call 
model_spec %>%  
    translate()

# Building the workflow
(model_workflow <- workflow() %>% 
   add_recipe(wine_rec) %>% 
   add_model(model_spec))

# Cross validation
(cv_folds <- vfold_cv(training_ratings, v = 5, repeats = 1))

# Set regular grid
grid_vals <- grid_regular(mtry(range = c(10, 18)), levels = 5)

model_res <- model_workflow %>% 
  tune_grid(
    resamples = cv_folds,
    grid = grid_vals,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(rmse)
  )
```

#### Figure 4:
```{r mtry}

# Evaluate how RF performs with different mtry values
fig4 <- model_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = mtry, y = mean)) +
  geom_point() + 
  geom_line() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(
    title = "Random Forest Performance by mtry",
    x = "mtry (number of variables tried at each split)",
    y = "Mean metric value (lower = better)",
    color = "mtry"
  ) +
  theme_minimal()

fig4

ggsave("writeup/fig4.png", plot = fig4, width = 6, height = 5, dpi = 300)

```

```{r randomforest continued again}

# final fit and evaluation
best_params <- model_res %>% 
  show_best(metric = "rmse") %>% 
  slice(1)

# Plug optimal hyperparameters into workflow & fit on all training data 
(final_model <- finalize_workflow(model_workflow, best_params))

final_fit <- final_model %>%
  fit(data = training_ratings)

# Inspect trained model
final_fit %>% 
  extract_fit_parsnip()

# Asses how model performs on unseen data
table3 <- predict(final_fit, testing_ratings) %>%
  bind_cols(testing_ratings) %>%
  metrics(truth = rating.x, estimate = .pred)

table3

```

#### Figure 5: Variable Importance Plot of top 20 words in reviews identified by Random Forest model 
```{r vip, fig.length = 10}

# Which features had the most influence on predictions 
fitted_model <- final_fit %>% 
    extract_fit_parsnip()
varimp <- vi(fitted_model)
varimp

# Draw VIP
fig5 <- vip(fitted_model, num_features = 20, geom = "col", 
    aesthetics = list(fill = "#CE677A")) +
    labs(
    title = "Variable Importance Plot of Top 20 Words Identified by Random Forest") +
  theme_minimal() 

fig5

ggsave("writeup/fig5.png", plot = fig5, width = 6, height = 5, dpi = 300)

```

#### Figure 6: Word cloud of top 50 words in reviews identified by Random Forest model
```{r rf wordcloud}

# Convert data for wordcloud
df_wordcloud <- vi(fitted_model) %>%
  arrange(desc(Importance)) %>%
  slice(1:50) %>% 
    select(word = Variable, freq = Importance)

# Draw wordcloud
fig6 <- wordcloud(df_wordcloud$word,
                  df_wordcloud$freq,
                  scale = c(5, 1),
                  colors = palette, 
                  bg.color = "white")
fig6
###################### HERE
ggsave("writeup/fig6.png", plot = fig6, width = 6, height = 5, dpi = 300)

```

### Step 2: OLS regression 
```{r regression}

# Filter dtm by top 20 words determined by RF
top_20 <- vip(fitted_model, num_features = 20)$data$Variable
df_ols <- dtm %>% 
  select(rating.x, all_of(top_20))

ols_model <- lm(rating.x ~ ., data = df_ols)
summary(ols_model)

### Table 4 ### 

# ols_tidy %>%
#   kable(format = "latex", booktabs = TRUE, digits = 3) %>%
#   save_kable("ols_results.tex")
```

```{r old regression}

# Tidy results
ols_results <- broom::tidy(ols_model) %>%
  arrange(desc(estimate))

# Filter out intercept and format
final_results <- ols_results %>%
  filter(term != "(Intercept)") %>%
  select(term, estimate, p.value) %>%
  mutate(
    effect = ifelse(estimate > 0, "Positive", "Negative"),
    term = fct_reorder(term, estimate)
  )
final_results

```

#### Figure 5: Plot of coefficients on OLS regression of top 20 words in reviews identified by RandomForest model
```{r fig5 OLSplot}

ggplot(final_results, aes(x = estimate, y = term, fill = effect)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(
    title = "Words Most Associated with Higher Wine Ratings",
    x = "Effect on Rating",
    y = "Word"
  ) +
  theme_bw()
  
```















