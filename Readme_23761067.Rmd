---
title: "Readme (23761067)"
author: "Talyah Greyling" 
output: 
    html_document:
        css: styles.css
---

### Goals: 
    (1) Transform and clean data
    (2) Exploratory data description of wine review data 
    (3) Statistical modeling of wine review data

### Setup defaults:          
```{r setup}

knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      cache = FALSE,
                      fig.align = "center",
                      fig.pos = "H", 
                      fig.width = 6, 
                      fig.height = 5) 
                      
```

### Housekeeping: 
```{r housekeeping}

# Clear environment:
rm(list = ls())            ############ uncomment before final submission 

# install.packages("webshot2")           ############# delete at end 
# POSSIBLY NEED: (rsample, caret, glmnet, vip, pdp, emoji, ggridges, ggmap, readxl, maps, viridis, eurostat, corrplot, GGally, reshape2, grid, rpart, rpart.plot, gt, knitr, cowplot, textdatavip, pdp, doParallel, foreach, ipred, ranger, gbm, xgboost)

# Load necessary packages:
pacman::p_load(bonsai,
               broom,
               dbbasic, 
               dplyr,
               ggplot2,
               ggwordcloud,
               glue,
               here, 
               kableExtra, 
               knitr,
               ldatuning,                   ############# update
               modeltime,
               pacman,
               pdp,
               randomForest,
               remotes,
               stopwords,
               stringr,
               targets,
               tidymodels,
               tidytext, 
               tidyverse,
               topicmodels,
               translateR,
               quanteda,
               wordcloud2,
               xtable)

# Suppress scientific notation:  
options(scipen = 999)

# Reproducibility:
set.seed(777)

# Set theme & colour palette: 
palette <- c("#163940", "#3A7370", "#FFC57B", "#FB9072", "#CE677A", "#5c2011")

my_theme <- theme(
  # Title, subtitle, and caption:
  plot.title = element_text(colour = "white", size = 16, family = "arial", hjust = 0.5,face = "bold"),
  plot.subtitle = element_text(colour = "white", size = 14, family = "arial"),
  plot.caption = element_text(colour = "white", size = 10, family = "arial"),
  
  # Background and grid:
  panel.background = element_blank(),
  plot.background = element_rect(fill = "black", color = "black"),
  panel.grid.major = element_line(color = "white", size = 0.1),
  panel.grid.minor = element_line(color = "white", size = 0.1),
  
  # Axis titles and labels:
  axis.title.x = element_text(colour = "white", size = 12,family = "arial", hjust = 0.5,face = "bold"),
  axis.title.y = element_text(colour = "white", size = 12,family = "arial", hjust = 0.5,face = "bold"),
  axis.text.y = element_text(colour = "white", size = 10,family = "arial"),
  axis.text.x = element_text(colour = "white", size = 10,family = "arial"),
  
  # Legend: 
  legend.position = "right",
  legend.text = element_text(colour = "white",size = 12, family = "arial"),
  legend.title = element_text(colour = "white",size = 12, family = "arial", hjust = 3,face = "bold"),
  legend.key = element_rect(fill = "black", color = "black"),
  legend.background = element_rect(fill = "black"),
  
  # Other
  axis.ticks = element_blank(),
  strip.text = element_text(colour = "white", size = 12, family = "arial", vjust = 1, hjust = 0.5)
)

# Import data: 
data <- readRDS("data/calitzdorp.rds")
               
```

### Explore dataset:
```{r explore data}

data %>%
    sample_n(1) %>% 
    t

```

#### Table 1: Head of dataframe 
```{r headdata, results = "asis"}

# Create empty table
datatab1 <- data[1:5,] %>% tibble::as_tibble()

# Populate with useful columns 
datatab1 <- datatab1 %>%
    select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count")) 

# Generate Table1
table1 <- kable(datatab1, "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "") %>%
  kable_styling(font_size = 10) 

# Print Table1
print(table1)


# ggsave(
#   table1.png,         
#   plot = last_plot(),  
#   path = "figures",    
#   width = 6,     # Width in inches (or `units` specified)
#   height = 5,    # Height in inches (or `units` specified)
#   units = "cm",   # Units for dimensions ("in", "cm", "mm", or "px")
#   dpi = 300,      # Dots per inch (resolution for raster formats)
#   device = png,  # Device function (e.g., "png", "pdf", "jpeg")
#   bg = "white",   # Background color
# )

#knitr::include_graphics("./figures/")
#gt()

# #Create variables for values that are the same for all observations??: 
# vintage_wine_region_country_regions_count <- data$vintage_wine_region_country_regions_count[1]
# vintage_wine_region_country_users_count <- data$vintage_wine_region_country_users_count[1]
# vintage_wine_region_country_wines_count <- data$vintage_wine_region_country_wines_count[1]
# vintage_wine_region_country_wineries_count <- data$vintage_wine_region_country_wineries_count[1]
# vintage_wine_region_country_regions_count

```

#### Table 2: Description of variables in datatab
```{r describe data, results = "asis"}

# Create and populate data frame
df1 <- data.frame(
    Variable = c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count"),
    Description = c("Identification code of review.",
                    "Rating out of 5 assigned to the wine by the reviewer",
                    "Note written about the wine by the reviewer",
                    "Language of the review",
                    "Moment the review was recorded in (Year month date time) format",
                    "List of 'flavor words' mentioned in the review",
                    "Whether the reviewer is a featured user",
                    "Whether the reviewer is a premium (paid subscription) user",
                    "Amount of followers the reviewer has", 
                    "Amount of users that the reviewer is following",
                    "Total amount of ratings that the reviewer has given",
                    "Total sum of all ratings given by the reviewer",
                    "Total amount of reviews that the reviewer has given",
                    "Amount of purchase orders made by the reviewee on Vivino",
                    "Identification code of the vintage reviewed",
                    "Year the grapes were harvested",
                    "A",
                    "A",
                    "A", 
                    "A", 
                    "A", 
                    "A",
                    "A",
                    "A",
                    "A", 
                    "A", 
                    "A", 
                    "A",
                    "A",
                    "A",
                    "A", 
                    "A", 
                    "A", 
                    "A")
    ) %>% tibble::as_tibble()

# Generate Table2
table2 <- kable(df1, "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "") %>%
  kable_styling(font_size = 10) 

# Print Table2
print(table2)

```

### Preparing dataset for analysis:
* Started with 2298 observations of 107 variables 
* Extracted the 3 variables useful for my research question 
* Only English observations were kept as using APIs for translation is too costly (1667 observations remaining)
* Unnested tokens (30 800 tokens were recorded)
* I followed the standard pre-processing steps of removing punctuation, numbers, symbols, characters and taking everything to lower case
* I also used the default tidyverse stop_words dataset to remove stop words (16 869 tokens remaining) using 3 respective lexicons: snowball (from the tm package), onix (from the ONIX text retrieval system) and smart (from the SMART information retrieval system). 
* All clean tokes were used in the random forrest to avoid unnecessary sampling bias. 
```{r prepare data}

# Get review data in clean token format 
review_tokens <- data %>%
    filter(str_detect(language, "en")) %>% # filter for only English entries
    select(c("id", "rating", "note")) %>%  # extract useful columns 
    unnest_tokens(input = note, 
                  output = word,
                  to_lower = TRUE,
                  strip_punct = TRUE,
                  strip_numeric = TRUE) %>%  
    mutate(word = gsub("_", "", word)) %>% 
    mutate(word = str_extract(word, "[[:alpha:]]+")) %>% 
    anti_join(stop_words, by = join_by(word)) 
 
```

### Concordance: exploratory analysis 
* See which words are popular
```{r popular}

# Calculate the average rating for each word and its count
words_ratings_counts <- review_tokens %>%
    group_by(word) %>%
    summarise(
        ave_rating = mean(rating, na.rm = TRUE),
        word_count = n(),
        .groups = "drop"
    )

# Create an index that determines popular words
words_popular <- words_ratings_counts %>%
    mutate(popularity_index = 0.8 * word_count + 0.2 * ave_rating) %>%
    filter(
        word_count > 10,
        word != "",!is.na(word),!is.na(ave_rating),!is.na(word_count),!is.na(popularity_index)
    ) %>%
    filter(!word %in% stop_words) %>%
    arrange(desc(popularity_index)) %>%
    select(c(word, popularity_index))

```

#### Figure 1: Word cloud of popular words in reviews based on an index 
```{r fig1 index wordcloud}

# Create Word Cloud
wordcloud2(words_popular, size = 1.6, color = palette, backgroundColor = "white")

```

### Step 1: RandomForest Method: variable selector (words as columns & ratings as rows) to determine the top N words (20/50) to filter only on those columns & draw word clouds, variable importance plots & PDP (Partial Dependence Plots)
* Draw wordclouds for both top 20 & 50 to see which is better & 50 presents better 
```{r RandomForest}

# Convert data to DTM format: 
dtm <- review_tokens %>%
    count(id, rating, word) %>%
    cast_dtm(id, word, n) %>%
    as.matrix() %>%
    as.data.frame() %>%
    mutate(rating = review_tokens %>%
               distinct(id, rating) %>%
               arrange(id) %>%
               pull(rating))  

# Use RandomForest for variable selection
colnames(dtm) <- make.names(colnames(dtm), unique = TRUE)
rf_model <- randomForest(rating ~ .,
                         data = dtm,
                         importance = TRUE,
                         ntree = 100)            ########## make 500? 

# Identify top 50 & 20 most important words
top_50_words <- importance(rf_model) %>%
    as.data.frame() %>%
    arrange(desc(`%IncMSE`)) %>%
    head(50) %>%
    rownames()

top_20_words <- importance(rf_model) %>%
    as.data.frame() %>%
    arrange(desc(`%IncMSE`)) %>%
    head(20) %>%
    rownames()

```

#### Figure 2: Word cloud of top 50 words in reviews identified by RandomForest model 
```{r fig2 RFwordcloud}

wordcloud50_data <- review_tokens %>%
  filter(word %in% top_50_words) %>%
  count(word)

# Create Word Cloud
wordcloud2(wordcloud50_data, size = 6, color = palette, backgroundColor = "white")

wordcloud20_data <- review_tokens %>%
  filter(word %in% top_20_words) %>%
  count(word)

# Create Word Cloud
wordcloud2(wordcloud20_data, size = 8, color = palette, backgroundColor = "white")

```

#### Figure 3: Variable Importance Plot of top 50 words in reviews identified by RandomForest model 
```{r fig3 VarImpPlot}

varImpPlot(rf_model, n.var = 20, main = "Top Words Predicting Wine Ratings")

```

#### Figure 4: Partial Dependence Plot of top 50 words in reviews identified by RandomForest model
```{r}

pdp_data <- pdp::partial(rf_model, pred.var = top_20_words[1:3], plot = TRUE, rug = TRUE)
pdp_data

```

### Step 2: run a regression of the best words (OLS) to get coefficients for their probability of determining good ratings 
```{r regression}

ols_data <- dtm %>%
  select(rating, top_20_words)

# Run OLS
ols_model <- lm(rating ~ ., data = ols_data)

# Tidy results
ols_results <- broom::tidy(ols_model) %>%
  arrange(desc(estimate))

# Filter out intercept and format
final_results <- ols_results %>%
  filter(term != "(Intercept)") %>%
  select(term, estimate, p.value) %>%
  mutate(
    effect = ifelse(estimate > 0, "Positive", "Negative"),
    term = fct_reorder(term, estimate)
  )

```

#### Figure 5: Plot of coefficients on OLS regression of top 20 words in reviews identified by RandomForest model
```{r fig5 OLSplot}

ggplot(final_results, aes(x = estimate, y = term, fill = effect)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(
    title = "Words Most Associated with Higher Wine Ratings",
    x = "Effect on Rating",
    y = "Word"
  ) +
  theme_bw()
  
```


### By the slides: 

```{r slides RF}

# Define training and testing sets for prediction
split_ratings <- initial_split(dtm, prop = 0.7)
training_ratings <- training(split_ratings)
testing_ratings <- testing(split_ratings)

# Confirm that training & testing data have similar ratings distributions
ggplot() + 
  geom_density(data = training_ratings, aes(rating), 
               alpha = 0.5, color = "#CE677A") + 
  geom_density(data = testing_ratings, aes(rating), 
               alpha = 0.5, color = "#3A7370") + 
  scale_x_continuous(labels = scales::comma) +
  theme_minimal() +
  labs(title = "Ratings Distribution: Train (Red) vs Test (Green)",
       x = "Rating", y = "Density")

# Feature engineering with recipes
wine_rec <- recipe(rating ~ ., data = training_ratings) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())

# RandomForest specification model
model_spec <- rand_forest(
  mtry = tune(),       
  min_n = 10,           
  trees = 100           
  ) %>%
  set_engine("ranger", num.threads = 10, 
             importance = "permutation") %>%  
  set_mode("regression")

# Inspect the low level call 
model_spec %>%  
    translate()

# Building the workflow
(model_workflow <- workflow() %>% 
   add_recipe(wine_rec) %>% 
   add_model(model_spec))

# Cross validation
(cv_folds <- vfold_cv(training_ratings, v = 5, repeats = 1))

# Set regular grid
grid_vals <- grid_regular(mtry(range = c(2, 12)), levels = 6)

model_res <- model_workflow %>% 
  tune_grid(
    resamples = cv_folds,
    grid = grid_vals,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(rmse)
  )

# Evaluate how RF performs with different mtry values
model_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = mtry, y = mean)) +
  geom_point() + 
  geom_line() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(
    title = "Random Forest Performance by mtry",
    x = "mtry (number of variables tried at each split)",
    y = "Mean metric value (lower = better)",
    color = "mtry"
  ) +
  theme_minimal()

```



















