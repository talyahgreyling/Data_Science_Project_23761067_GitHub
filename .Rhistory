table3 <- predict(final_fit, testing_ratings) %>%
bind_cols(testing_ratings) %>%
metrics(truth = rating.x, estimate = .pred)
table3
# RandomForest recipe
wine_rec <- recipe(rating.x ~ ., data = training_ratings) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_numeric_predictors())
# RandomForest specification model
model_spec <- rand_forest(
mtry = tune(),
min_n = 10,
trees = 100
) %>%
set_engine("ranger", num.threads = 10,
importance = "permutation") %>%
set_mode("regression")
# Inspect the low level call
model_spec %>%
translate()
# Building the workflow
(model_workflow <- workflow() %>%
add_recipe(wine_rec) %>%
add_model(model_spec))
# Cross validation
(cv_folds <- vfold_cv(training_ratings, v = 5, repeats = 1))
# Set regular grid
grid_vals <- grid_regular(mtry(range = c(10, 18)), levels = 5)
model_res <- model_workflow %>%
tune_grid(
resamples = cv_folds,
grid = grid_vals,
control = control_grid(save_pred = TRUE),
metrics = metric_set(rmse)
)
# final fit and evaluation
best_params <- model_res %>%
show_best(metric = "rmse") %>%
slice(1)
# Plug optimal hyperparameters into workflow & fit on all training data
(final_model <- finalize_workflow(model_workflow, best_params))
final_fit <- final_model %>%
fit(data = training_ratings)
# Inspect trained model
final_fit %>%
extract_fit_parsnip()
# Asses how model performs on unseen data
table3 <- predict(final_fit, testing_ratings) %>%
bind_cols(testing_ratings) %>%
metrics(truth = rating.x, estimate = .pred)
table3
# RandomForest recipe
wine_rec <- recipe(rating.x ~ ., data = training_ratings) %>%
step_zv(all_numeric_predictors())
# RandomForest specification model
model_spec <- rand_forest(
mtry = tune(),
min_n = 10,
trees = 100
) %>%
set_engine("ranger", num.threads = 10,
importance = "permutation") %>%
set_mode("regression")
# Inspect the low level call
model_spec %>%
translate()
# Building the workflow
(model_workflow <- workflow() %>%
add_recipe(wine_rec) %>%
add_model(model_spec))
# Cross validation
(cv_folds <- vfold_cv(training_ratings, v = 5, repeats = 1))
# Set regular grid
grid_vals <- grid_regular(mtry(range = c(10, 18)), levels = 5)
model_res <- model_workflow %>%
tune_grid(
resamples = cv_folds,
grid = grid_vals,
control = control_grid(save_pred = TRUE),
metrics = metric_set(rmse)
)
# final fit and evaluation
best_params <- model_res %>%
show_best(metric = "rmse") %>%
slice(1)
# Plug optimal hyperparameters into workflow & fit on all training data
(final_model <- finalize_workflow(model_workflow, best_params))
final_fit <- final_model %>%
fit(data = training_ratings)
# Inspect trained model
final_fit %>%
extract_fit_parsnip()
# Asses how model performs on unseen data
table3 <- predict(final_fit, testing_ratings) %>%
bind_cols(testing_ratings) %>%
metrics(truth = rating.x, estimate = .pred)
table3
# Create empty table
datatab1 <- data[1:5,] %>% tibble::as_tibble()
# Populate with useful columns
datatab1 <- datatab1 %>%
select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count"))
# Generate Table1
table1 <- kable(datatab1, "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "") %>%
kable_styling(font_size = 10)
table1
# Create empty table
datatab1 <- data[1:5,] %>% tibble::as_tibble()
# Populate with useful columns
datatab1 <- datatab1 %>%
select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count"))
# Generate Table1
table1 <- kable(datatab1, format = "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "Head of data frame") %>%
kable_styling(bootstrap_options = c("striped", "hover"), font_size = 10)
table1
# Create empty table
datatab1 <- data[1:5,] %>% tibble::as_tibble()
# Populate with useful columns
datatab1 <- datatab1 %>%
select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count"))
# Generate Table1
table1 <- kable(datatab1, format = "html", booktabs = TRUE, longtable = FALSE, linesep = "", caption = "Head of data frame") %>%
kable_styling(bootstrap_options = c("striped", "hover"), font_size = 10)
table1
View(datatab1)
# Load necessary packages
pacman::p_load(bonsai,
broom,
dbbasic,
dplyr,
ggplot2,
ggwordcloud,
glue,
here,
kableExtra,
knitr,
ldatuning,                   ############# update @ both rmd's
modeltime,
pacman,
pdp,
quanteda,
randomForest,
readr,
remotes,
stopwords,
stringr,
targets,
tibble,
tidymodels,
tidyr,
tidytext,
tidyverse,
topicmodels,
vip,
wordcloud,
xtable)
# Create empty table
datatab1 <- data[1:5, ] %>%
as_tibble()
# Populate with useful columns
datatab1 <- datatab1 %>%
select(c("id", "rating", "note", "language", "created_at", "flavor_word_matches", "user_is_featured", "user_is_premium", "user_statistics_followers_count", "user_statistics_followings_count", "user_statistics_ratings_count", "user_statistics_ratings_sum", "user_statistics_reviews_count", "user_statistics_purchase_order_count", "vintage_id", "vintage_year", "vintage_has_valid_ratings", "vintage_statistics_ratings_count", "vintage_statistics_ratings_average", "vintage_statistics_labels_count", "vintage_statistics_reviews_count", "vintage_wine_id", "vintage_wine_name", "vintage_wine_winery_name", "vintage_wine_winery_statistics_ratings_count", "vintage_wine_winery_statistics_ratings_average", "vintage_wine_winery_statistics_labels_count", "vintage_wine_winery_statistics_wines_count", "vintage_wine_statistics_ratings_count", "vintage_wine_statistics_ratings_average", "vintage_wine_statistics_labels_count", "vintage_wine_statistics_vintages_count", "activity_statistics_likes_count", "activity_statistics_comments_count"))
# Generate Table1
table1 <- kable(datatab1, format = "html", booktabs = TRUE, linesep = "", caption = "") %>%
kable_styling(full_width = FALSE, font_size = 12) %>%
scroll_box(width = "100%", height = "500px")
print(table1)
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
cache = FALSE,
fig.align = "center",
fig.pos = "H",
fig.width = 6,
fig.height = 5)
# Clear environment
rm(list = ls())
# Load necessary packages
pacman::p_load(bonsai,
broom,
dbbasic,
dplyr,
ggplot2,
ggwordcloud,
glue,
here,
kableExtra,
knitr,
ldatuning,
modeltime,
pacman,
pdp,
quanteda,
randomForest,
readr,
remotes,
stopwords,
stringr,
targets,
tibble,
tidymodels,
tidyr,
tidytext,
tidyverse,
topicmodels,
vip,
wordcloud,
xtable)
# Suppress scientific notation
options(scipen = 999)
# Reproducibility
set.seed(777)
# Set theme & colour palette
palette <- c("#4d8049", "#3A7370", "#FFC57B", "#FB9072", "#CE677A", "#9c0315")
# Import data
data <- readRDS("data/calitzdorp.rds")
data %>%
sample_n(1) %>%
t
# Create and populate data frame
df1 <- data.frame(
Variable = c("id", "rating", "note", "language"),
Description = c("Identification code of review",
"Rating out of 5 assigned to the wine by the reviewer",
"Note written about the wine by the reviewer",
"Language of the review"))
table1 <- print(xtable(df1),
type = "html",
include.rownames = TRUE,
print.results = FALSE)
table1
# Get review data in clean token format
review_tokens <- data %>%
filter(str_detect(language, "en")) %>% # filter for only English entries
select(c(review_id = "id", "rating", "note")) %>%  # extract useful columns
unnest_tokens(input = note,
output = word,
to_lower = TRUE,
strip_punct = TRUE,
strip_numeric = TRUE) %>%
mutate(word = gsub("_", "", word)) %>%
mutate(word = str_extract(word, "[[:alpha:]]+")) %>%
anti_join(stop_words, by = join_by(word)) # remove stop words
# Calculate the average rating for each word and its count
words_ratings_counts <- review_tokens %>%
group_by(word) %>%
summarise(
ave_rating = mean(rating, na.rm = TRUE),
word_count = n(),
.groups = "drop"
)
# Plot histogram
fig1 <- ggplot(words_ratings_counts, aes(x = ave_rating)) +
geom_histogram(aes(y = ..count..), binwidth =0.5, bins = 30, fill = "#3A7370", color = "black", alpha = 1) +
theme_minimal() +
labs(title = "Histogram of average ratings of review tokens",
x = "Average Rating",
y = "Frequency")
fig1
ggsave("writeup/fig1.png", plot = fig1, width = 6, height = 5, dpi = 300)
# Create an index that determines popular words
words_popular <- words_ratings_counts %>%
mutate(popularity_index = 0.8 * word_count + 0.2 * ave_rating) %>%
filter(
word_count > 10,
word != "",!is.na(word),!is.na(ave_rating),!is.na(word_count),!is.na(popularity_index)
) %>%
filter(!word %in% stop_words) %>%
arrange(desc(popularity_index)) %>%
select(c(word, popularity_index))
# Create Word Cloud
fig2 <- wordcloud(words_popular$word,
words_popular$popularity_index,
scale = c(4, 1),
colors = palette,
bg.color = "white")
fig2
ggsave("writeup/fig2.png", plot = fig2, width = 6, height = 5, dpi = 300)
# Convert data to DTM format:
dtm <- review_tokens %>%
group_by(review_id, word) %>%
summarise(count = n(), .groups = "drop") %>%
pivot_wider(names_from = word,
values_from = count,
values_fill = list(count = 0))
# Add back rating & drop review_id
ratings <- review_tokens %>%
select(review_id, rating) %>%
distinct()
dtm <- left_join(ratings, dtm, by = "review_id") %>%
select(-review_id)
# Define training and testing sets for prediction
split_ratings <- initial_split(dtm, prop = 0.7)
training_ratings <- training(split_ratings)
testing_ratings <- testing(split_ratings)
# Confirm that training & testing data have similar ratings distributions
fig3 <- ggplot() +
geom_density(data = training_ratings, aes(rating.x), linewidth = 1.5, alpha = 0.5, color = "#CE677A") +
geom_density(data = testing_ratings, aes(rating.x), linewidth = 1.5, alpha = 0.5, color = "#3A7370") +
scale_x_continuous(labels = scales::comma) +
theme_minimal() +
labs(title = "Ratings Distribution: Train (Red) vs Test (Green)", x = "Rating", y = "Density")
fig3
ggsave("writeup/fig3.png", plot = fig3, width = 6, height = 5, dpi = 300)
# RandomForest recipe
wine_rec <- recipe(rating.x ~ ., data = training_ratings) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_numeric_predictors()) %>%
step_normalize(all_numeric_predictors())
# RandomForest specification model
model_spec <- rand_forest(
mtry = tune(),
min_n = 10,
trees = 100
) %>%
set_engine("ranger", num.threads = 10,
importance = "permutation") %>%
set_mode("regression")
# Inspect the low level call
model_spec %>%
translate()
# Building the workflow
(model_workflow <- workflow() %>%
add_recipe(wine_rec) %>%
add_model(model_spec))
# Cross validation
(cv_folds <- vfold_cv(training_ratings, v = 5, repeats = 1))
# Set regular grid
grid_vals <- grid_regular(mtry(range = c(10, 18)), levels = 5)
model_res <- model_workflow %>%
tune_grid(
resamples = cv_folds,
grid = grid_vals,
control = control_grid(save_pred = TRUE),
metrics = metric_set(rmse)
)
# Evaluate how RF performs with different mtry values
fig4 <- model_res %>%
collect_metrics() %>%
ggplot(aes(x = mtry, y = mean)) +
geom_point() +
geom_line() +
facet_wrap(~.metric, scales = "free_y") +
labs(
title = "Random Forest Performance by mtry",
x = "mtry (number of variables tried at each split)",
y = "Mean metric value (lower = better)",
color = "mtry"
) +
theme_minimal()
fig4
ggsave("writeup/fig4.png", plot = fig4, width = 6, height = 5, dpi = 300)
# final fit and evaluation
best_params <- model_res %>%
show_best(metric = "rmse") %>%
slice(1)
# Plug optimal hyperparameters into workflow & fit on all training data
(final_model <- finalize_workflow(model_workflow, best_params))
final_fit <- final_model %>%
fit(data = training_ratings)
# Inspect trained model
final_fit %>%
extract_fit_parsnip()
# Asses how model performs on unseen data
metricsdata <- predict(final_fit, testing_ratings) %>%
bind_cols(testing_ratings) %>%
metrics(truth = rating.x, estimate = .pred)
xtab_metrics <- xtable(metricsdata,
caption = "Model Performance Metrics",
digits = c(0, 0, 4, 4))
table2 <- print(xtable(xtab_metrics),
type = "html",
include.rownames = FALSE,
caption.placement = "top",
print.results = FALSE)
table2
# Which features had the most influence on predictions
fitted_model <- final_fit %>%
extract_fit_parsnip()
varimp <- vi(fitted_model)
varimp
# Draw VIP
fig5 <- vip(fitted_model, num_features = 20, geom = "col",
aesthetics = list(fill = "#CE677A")) +
labs(
title = "Variable Importance Plot of Top 20 Words Identified by Random Forest") +
theme_minimal()
fig5
ggsave("writeup/fig5.png", plot = fig5, width = 6, height = 5, dpi = 300)
# Convert data for wordcloud
df_wordcloud <- vi(fitted_model) %>%
arrange(desc(Importance)) %>%
slice(1:50) %>%
select(word = Variable, freq = Importance)
# Draw wordcloud
fig6 <- wordcloud(df_wordcloud$word,
df_wordcloud$freq,
scale = c(5, 1),
colors = palette,
bg.color = "white")
fig6
ggsave("writeup/fig6.png", plot = fig6, width = 6, height = 5, dpi = 300)
# Filter dtm by top 20 words determined by RF
top_20 <- vip(fitted_model, num_features = 20)$data$Variable
df_ols <- dtm %>%
select(rating.x, all_of(top_20))
ols_model <- lm(rating.x ~ ., data = df_ols)
summary(ols_model)
ols_table <- xtable(ols_model,
caption = "OLS Regression Results (Top 20 Features)")
print(ols_table,
type = "html",
include.rownames = TRUE,
caption.placement = "top",
html.table.attributes = 'class="table table-striped" style="width:100%;"')
# Tidy results
ols_results <- broom::tidy(ols_model) %>%
arrange(desc(estimate))
# Filter out intercept and format
final_results <- ols_results %>%
filter(term != "(Intercept)") %>%
select(term, estimate, p.value) %>%
mutate(
effect = ifelse(estimate > 0, "Positive", "Negative"),
term = fct_reorder(term, estimate)
)
final_results
fig7 <-  ggplot(final_results, aes(x = estimate, y = term, fill = effect)) +
geom_col() +
scale_fill_manual(values = c("#9c0315", "#4d8049")) +
labs(
title = "Words with Strongest Correlation to Wine Ratings",
x = "Effect on Rating",
y = "Word"
) +
theme_bw()
fig7
ggsave("writeup/fig7.png", plot = fig7, width = 6, height = 5, dpi = 300)
xtab_metrics <- xtable(metricsdata,
caption = "Model Performance Metrics",
digits = c(0, 0, 4, 4))
table2 <- print(xtable(xtab_metrics),
type = "html",
include.rownames = FALSE,
caption.placement = "top",
print.results = FALSE)
table2
# Create Word Cloud
fig2 <- ggplot(words_popular, aes(label = word, size = popularity_index)) +
geom_text_wordcloud_area(color = "black") +
scale_size_area(max_size = 20) +
theme_minimal()
fig2
ggsave("writeup/fig2.png", plot = fig2, width = 6, height = 5, dpi = 300)
fig2 <- ggplot(words_popular, aes(label = word, size = popularity_index, color = palette)) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 20) +
scale_color_identity() +
theme_minimal()
fig2
# Set palette
words_popular$color <- sample(palette, nrow(words_popular), replace = TRUE)
View(words_popular)
# Set palette
words_popular$assigned_color <- sample(palette, nrow(words_popular), replace = TRUE)
# Create Word Cloud
fig2 <- ggplot(words_popular, aes(label = word, size = popularity_index, color = assigned_color)) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 20) +
scale_color_identity() +
theme_minimal()
fig2
fig2 <- ggplot(words_popular, aes(label = word, size = popularity_index, color = assigned_color)) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 40) +
scale_color_identity() +
theme_minimal()
fig2
top50 <- words_popular %>%
slice_max(order_by = popularity_index, n = 50)
# Set palette
top50$assigned_color <- sample(palette, nrow(words_popular), replace = TRUE)
View(top50)
top50 <- words_popular %>%
slice_max(order_by = popularity_index, n = 50)
# Set palette
top50$assigned_color <- sample(palette, nrow(top50), replace = TRUE)
# Create Word Cloud
fig2 <- ggplot(top50, aes(label = word, size = popularity_index, color = assigned_color)) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 40) +
scale_color_identity() +
theme_minimal()
fig2
ggsave("writeup/fig2.png", plot = fig2, width = 6, height = 5, dpi = 300)
View(df_wordcloud)
# Convert data for wordcloud
df_wordcloud <- vi(fitted_model) %>%
arrange(desc(Importance)) %>%
slice(1:50) %>%
select(word = Variable, freq = Importance)
# Set palette
df_wordcloud$assigned_color <- sample(palette, nrow(df_wordcloud), replace = TRUE)
# Create Word Cloud
fig6 <- ggplot(df_wordcloud, aes(label = word, size = freq, color = assigned_color)) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 40) +
scale_color_identity() +
theme_minimal()
fig6
ggsave("writeup/fig6.png", plot = fig6, width = 6, height = 5, dpi = 300)
